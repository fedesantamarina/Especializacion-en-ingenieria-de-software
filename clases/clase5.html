<div class="clase-content">
    <h1>Clase 5: Elementos Avanzados de Bases de Datos</h1>

    <div class="clase-meta">
        <div class="meta-item">
            <strong>Módulo:</strong> Tecnologías Avanzadas
        </div>
        <div class="meta-item">
            <strong>Duración:</strong> 4 horas
        </div>
        <div class="meta-item">
            <strong>Nivel:</strong> Avanzado
        </div>
    </div>

    <h2>1. Evolución de los Sistemas de Gestión de Bases de Datos</h2>

    <p>
        Los sistemas de gestión de bases de datos (SGBD) han experimentado una evolución significativa desde los primeros modelos jerárquicos y de red hasta los sistemas relacionales que dominaron la industria durante décadas. El modelo relacional, propuesto por Edgar F. Codd en 1970, estableció fundamentos teóricos sólidos basados en álgebra relacional y cálculo relacional, proporcionando independencia de datos, lenguajes declarativos de consulta como SQL, y propiedades ACID (Atomicidad, Consistencia, Aislamiento, Durabilidad) que garantizan integridad transaccional. Sin embargo, las demandas contemporáneas de sistemas distribuidos masivamente escalables, datos semi-estructurados heterogéneos, y latencias ultra-bajas han motivado el surgimiento de paradigmas alternativos.
    </p>

    <p>
        El movimiento NoSQL (Not Only SQL) emergió a fines de la década de 2000 como respuesta a limitaciones de bases de datos relacionales para ciertos casos de uso. Sistemas distribuidos masivos como los de Google, Amazon y Facebook requerían escalabilidad horizontal, alta disponibilidad y tolerancia a particiones que los SGBD relacionales tradicionales no proporcionaban eficientemente. El teorema CAP (Consistency, Availability, Partition Tolerance), formulado por Eric Brewer, establece que sistemas distribuidos solo pueden garantizar simultáneamente dos de estas tres propiedades. Esta limitación fundamental impulsó desarrollo de diversos sistemas NoSQL que priorizan disponibilidad y tolerancia a particiones sobre consistencia fuerte, aceptando consistencia eventual.
    </p>

    <div class="info-box">
        <p><strong>Teorema CAP:</strong> En presencia de particiones de red (P), un sistema distribuido debe elegir entre Consistencia (C) y Disponibilidad (A). Esta limitación fundamental influye profundamente en el diseño de sistemas de bases de datos distribuidas.</p>
    </div>

    <h3>1.1 El Paradigma NoSQL y sus Modelos de Datos</h3>

    <p>
        Los sistemas NoSQL abarcan múltiples modelos de datos, cada uno optimizado para casos de uso específicos. Las bases de datos documentales, como MongoDB, CouchDB o Amazon DocumentDB, almacenan datos como documentos semi-estructurados (típicamente JSON o BSON) que pueden anidarse y variar en estructura. Este modelo resulta natural para aplicaciones donde los datos no se ajustan fácilmente a esquemas tabulares rígidos. Las bases de datos de grafos, como Neo4j, Amazon Neptune o JanusGraph, representan explícitamente relaciones entre entidades, optimizando consultas que atraviesan relaciones complejas, apropiadas para redes sociales, sistemas de recomendación, o análisis de fraude.
    </p>

    <p>
        Las bases de datos de clave-valor, como Redis, Amazon DynamoDB o Riak, proporcionan la abstracción más simple: almacenan valores asociados a claves únicas, optimizando para lecturas y escrituras extremadamente rápidas. Las bases de datos columnares o de familia de columnas, como Apache Cassandra, HBase o ScyllaDB, organizan datos por columnas en lugar de filas, optimizando para consultas analíticas que procesan subconjuntos de columnas sobre muchas filas. Cada modelo de datos presenta trade-offs específicos en términos de flexibilidad de consultas, rendimiento, escalabilidad y complejidad operacional.
    </p>

    <div class="mermaid">
    graph TB
        A[Bases de Datos] --> B[SQL Relacionales]
        A --> C[NoSQL]

        B --> B1[MySQL]
        B --> B2[PostgreSQL]
        B --> B3[Oracle]

        C --> C1[Documentales]
        C --> C2[Clave-Valor]
        C --> C3[Grafos]
        C --> C4[Columnares]

        C1 --> C1A[MongoDB]
        C2 --> C2A[Redis]
        C3 --> C3A[Neo4j]
        C4 --> C4A[Cassandra]

        style B fill:#3498db
        style C fill:#e74c3c
        style A fill:#9b59b6
    </div>

    <h3>1.2 Persistencia Políglota y Arquitecturas Híbridas</h3>

    <p>
        El concepto de persistencia políglota reconoce que diferentes partes de una aplicación pueden beneficiarse de diferentes tecnologías de persistencia. En lugar de forzar todos los datos a un único SGBD, arquitecturas modernas combinan múltiples sistemas de bases de datos, cada uno optimizado para requisitos específicos. Por ejemplo, una aplicación de comercio electrónico podría usar una base de datos relacional para datos transaccionales críticos (pedidos, pagos), una base de datos documental para catálogo de productos con atributos variables, una base de datos de grafos para recomendaciones, y Redis para caché y sesiones de usuario.
    </p>

    <p>
        Esta heterogeneidad introduce complejidades significativas: sincronización de datos entre sistemas, gestión de transacciones distribuidas, consistencia eventual, y mayor complejidad operacional. Los patrones arquitectónicos como CQRS (Command Query Responsibility Segregation) y Event Sourcing facilitan gestión de persistencia políglota mediante separación de modelos de escritura y lectura, y captura de cambios como secuencia inmutable de eventos. La decisión de adoptar persistencia políglota debe balancear beneficios de especialización contra costos de complejidad adicional.
    </p>

    <h2>2. Optimización de Rendimiento en Bases de Datos</h2>

    <p>
        El rendimiento de bases de datos impacta críticamente la experiencia de usuario y la escalabilidad de aplicaciones. La optimización de rendimiento requiere comprensión profunda de múltiples niveles: diseño lógico del esquema, diseño físico de almacenamiento, indexación apropiada, optimización de consultas, configuración del SGBD, y arquitectura de hardware subyacente. Los cuellos de botella pueden emerger en diversos puntos: I/O de disco, memoria insuficiente, contención de locks, o consultas mal optimizadas.
    </p>

    <h3>2.1 Estrategias de Indexación Avanzadas</h3>

    <p>
        Los índices constituyen estructuras de datos auxiliares que aceleran consultas a costa de espacio adicional y sobrecarga en escrituras. Los índices B-tree, estructura por defecto en la mayoría de SGBD relacionales, proporcionan búsquedas, inserciones y eliminaciones logarítmicas, y soportan eficientemente búsquedas por rangos. Los índices hash ofrecen búsquedas de complejidad constante para búsquedas por igualdad, pero no soportan rangos. Los índices bitmap resultan eficientes para columnas con baja cardinalidad, permitiendo operaciones lógicas rápidas.
    </p>

    <p>
        Los índices compuestos (multi-columna) aceleran consultas que filtran por múltiples columnas, pero el orden de columnas impacta significativamente efectividad. Los índices covering o inclusivos incluyen columnas adicionales no indexadas, permitiendo satisfacer consultas enteramente desde el índice sin acceder a la tabla. Los índices parciales indexan solo subconjunto de filas satisfaciendo predicado, reduciendo tamaño. Los índices funcionales indexan resultado de funciones aplicadas a columnas. La selección apropiada de índices requiere analizar patrones de consulta, considerando trade-offs entre beneficios en lecturas versus sobrecarga en escrituras y espacio consumido.
    </p>

    <h3>2.2 Optimización de Consultas y Planes de Ejecución</h3>

    <p>
        Los optimizadores de consultas de SGBD modernos transforman consultas SQL declarativas en planes de ejecución eficientes. El proceso involucra parseo de SQL, validación semántica, generación de múltiples planes de ejecución alternativos, estimación de costo de cada plan basado en estadísticas sobre datos y selectividad de predicados, y selección del plan de costo mínimo estimado. Sin embargo, estimaciones pueden ser inexactas debido a estadísticas desactualizadas, distribuciones de datos no uniformes, o correlaciones entre columnas no capturadas.
    </p>

    <p>
        El análisis de planes de ejecución (EXPLAIN PLAN) revela cómo el optimizador ejecutará una consulta, identificando operaciones costosas como table scans completos, joins ineficientes, o sorts de grandes volúmenes. La optimización puede involucrar reescritura de consultas para facilitar uso de índices, adición de hints al optimizador, actualización de estadísticas, o modificación de esquema. Técnicas avanzadas incluyen materialización de vistas para pre-computar joins complejos, particionamiento de tablas para permitir eliminación de particiones durante consultas, y paralelización de consultas.
    </p>

    <h3>2.3 Gestión de Transacciones y Control de Concurrencia</h3>

    <p>
        Las propiedades ACID garantizan integridad transaccional, pero su implementación impacta rendimiento, especialmente en sistemas con alta concurrencia. Los protocolos de control de concurrencia gestionan acceso concurrente a datos compartidos. El two-phase locking (2PL) adquiere locks antes de acceder datos y libera locks solo después de completar transacción, garantizando serializabilidad pero potencialmente causando deadlocks y reduciendo concurrencia. Los algoritmos optimistas permiten transacciones proceder sin locks, validando al commit que no hubo conflictos, apropiados cuando conflictos son raros.
    </p>

    <p>
        Los niveles de aislamiento (Read Uncommitted, Read Committed, Repeatable Read, Serializable) permiten trade-offs entre consistencia y rendimiento. Niveles más débiles permiten fenómenos de concurrencia como dirty reads, non-repeatable reads o phantom reads, pero ofrecen mayor throughput. El Multi-Version Concurrency Control (MVCC), usado por PostgreSQL, Oracle y otros, mantiene múltiples versiones de datos, permitiendo lecturas sin bloquear escrituras y vice versa, incrementando significativamente concurrencia. La configuración apropiada de niveles de aislamiento requiere comprender requisitos de consistencia de cada transacción.
    </p>

    <h2>3. Big Data y Procesamiento Distribuido</h2>

    <p>
        El término "Big Data" refiere a conjuntos de datos cuyo volumen, velocidad de generación, o variedad exceden capacidades de herramientas tradicionales de gestión de datos. Las "tres V" clásicas —Volumen (escala de datos), Velocidad (velocidad de generación y procesamiento), y Variedad (diversidad de tipos de datos)— caracterizan desafíos de Big Data. A estas frecuentemente se añaden Veracidad (calidad e incertidumbre de datos) y Valor (utilidad extraíble de datos). Abordar estos desafíos requiere arquitecturas distribuidas que escalan horizontalmente agregando nodos commodity.
    </p>

    <h3>3.1 Ecosistema Hadoop y MapReduce</h3>

    <p>
        Apache Hadoop estableció fundamentos para procesamiento distribuido de Big Data mediante dos componentes principales: HDFS (Hadoop Distributed File System) para almacenamiento distribuido tolerante a fallos, y MapReduce como modelo de programación para procesamiento paralelo. HDFS divide archivos en bloques (típicamente 128MB o 256MB) replicados en múltiples nodos, proporcionando alta throughput de lectura y tolerancia a fallos de nodos individuales. MapReduce descompone computaciones en fases map (procesamiento paralelo de datos locales) y reduce (agregación de resultados), ocultando complejidades de distribución, paralelización y tolerancia a fallos.
    </p>

    <p>
        Sin embargo, MapReduce presenta limitaciones significativas: latencia alta (no apropiado para consultas interactivas), overhead de I/O (resultados intermedios se escriben a disco), y expresividad limitada (algoritmos iterativos requieren múltiples jobs MapReduce encadenados). Estas limitaciones motivaron desarrollo de frameworks de nueva generación como Apache Spark, que mantiene datos intermedios en memoria cuando es posible, soporta procesamiento iterativo eficiente, y proporciona APIs de alto nivel incluyendo Spark SQL para consultas estructuradas, MLlib para machine learning, y GraphX para procesamiento de grafos.
    </p>

    <div class="mermaid">
    graph LR
        A[Fuentes de Datos] --> B[Ingesta]
        B --> C[HDFS/Almacenamiento Distribuido]
        C --> D[Procesamiento Spark]
        D --> E[Almacenamiento]
        E --> F[Visualización/Analytics]

        subgraph Capas del Ecosistema Big Data
            B
            C
            D
            E
        end

        style D fill:#e74c3c
        style C fill:#3498db
        style F fill:#2ecc71
    </div>

    <h3>3.2 Procesamiento de Streams en Tiempo Real</h3>

    <p>
        Muchas aplicaciones modernas requieren procesamiento de streams de datos en tiempo real o near-real-time, donde latencias de segundos o menos resultan críticas. Casos de uso incluyen detección de fraude, monitoreo de sistemas, análisis de clickstreams, y trading algorítmico. Los sistemas de procesamiento de streams como Apache Kafka, Apache Flink, Apache Storm, y Amazon Kinesis proporcionan abstracciones para consumir, procesar y producir streams continuos de eventos.
    </p>

    <p>
        Apache Kafka se ha establecido como plataforma estándar de facto para streaming de datos, proporcionando un log distribuido, particionado y replicado que actúa como buffer entre productores y consumidores de eventos. Kafka garantiza ordenamiento dentro de particiones, durabilidad configurable, y throughput excepcional. Apache Flink proporciona procesamiento de streams con semánticas exactly-once, windowing flexible, y gestión de estado tolerante a fallos. La arquitectura Lambda y su variante Kappa proponen patrones arquitectónicos que combinan procesamiento batch y stream para casos donde se requieren ambos paradigmas.
    </p>

    <h3>3.3 Data Lakes y Data Warehouses Modernos</h3>

    <p>
        Los data warehouses tradicionales almacenan datos estructurados, limpios y modelados (típicamente esquemas estrella o copo de nieve) optimizados para consultas analíticas. Los data lakes, en contraste, almacenan datos crudos en formato nativo (estructurados, semi-estructurados, no estructurados) a gran escala, frecuentemente en almacenamiento de objetos como Amazon S3, Azure Data Lake o Google Cloud Storage. Los data lakes proporcionan flexibilidad para exploración y análisis ad-hoc, pero pueden degenerar en "data swamps" sin gobernanza apropiada.
    </p>

    <p>
        Arquitecturas modernas frecuentemente adoptan enfoque híbrido: data lakes para almacenamiento bruto flexible, con capas de procesamiento que refinan datos y los cargan en data warehouses para analytics de alta performance. Tecnologías como Delta Lake, Apache Iceberg, y Apache Hudi proporcionan capacidades tipo base de datos (transacciones ACID, time travel, upserts) sobre data lakes, difuminando fronteras entre data lakes y warehouses. Los data warehouses cloud-native como Snowflake, Amazon Redshift, Google BigQuery y Azure Synapse proporcionan escalabilidad elástica, separación de almacenamiento y cómputo, y pricing basado en uso.
    </p>

    <h2>4. Bases de Datos Especializadas</h2>

    <p>
        Más allá de los SGBD generalistas, han surgido bases de datos altamente especializadas optimizadas para casos de uso específicos. Estas bases de datos sacrifican generalidad por rendimiento excepcional en su nicho. Su proliferación refleja reconocimiento de que no existe solución universal óptima para todos los casos de uso.
    </p>

    <h3>4.1 Bases de Datos de Series Temporales</h3>

    <p>
        Las bases de datos de series temporales (TSDB) están optimizadas para datos timestamped, típicamente generados por sensores, métricas de sistemas, datos financieros, o eventos de aplicaciones. Ejemplos incluyen InfluxDB, TimescaleDB, Prometheus, y OpenTSDB. Estas bases optimizan para ingestión de alta throughput de datos ordenados temporalmente, compresión eficiente aprovechando patrones temporales, y consultas sobre ventanas de tiempo. Funciones especializadas soportan downsampling, agregaciones temporales, y análisis de tendencias.
    </p>

    <h3>4.2 Bases de Datos Espaciales</h3>

    <p>
        Las bases de datos espaciales gestionan datos geoespaciales, soportando tipos de datos geométricos (puntos, líneas, polígonos) y operaciones espaciales (intersección, distancia, containment). PostGIS extiende PostgreSQL con capacidades espaciales comprehensivas. MongoDB incluye índices geoespaciales para consultas de proximidad. Las aplicaciones incluyen sistemas de información geográfica (GIS), servicios basados en ubicación, routing, y análisis territorial. La indexación espacial mediante estructuras como R-trees permite búsquedas eficientes sobre datos espaciales que de otro modo requerirían búsquedas exhaustivas costosas.
    </p>

    <h3>4.3 Bases de Datos de Búsqueda</h3>

    <p>
        Los motores de búsqueda especializados como Elasticsearch, Apache Solr y Amazon CloudSearch proporcionan búsqueda full-text eficiente, análisis de texto, y agregaciones complejas. Estas tecnologías indexan texto usando estructuras como índices invertidos, soportan búsquedas fuzzy, relevance scoring, highlighting, y faceting. Casos de uso incluyen búsqueda en sitios web, análisis de logs, y búsqueda empresarial. Elasticsearch se ha popularizado como componente del stack ELK (Elasticsearch, Logstash, Kibana) para ingesta, indexación, búsqueda y visualización de logs y métricas.
    </p>

    <h2>5. Tendencias Emergentes en Gestión de Datos</h2>

    <p>
        El campo de gestión de datos continúa evolucionando rápidamente, impulsado por nuevos requisitos de aplicaciones y avances tecnológicos. Varias tendencias emergentes prometen transformar significativamente paisajes de gestión de datos en años venideros.
    </p>

    <h3>5.1 Bases de Datos Autónomas</h3>

    <p>
        Las bases de datos autónomas aplican inteligencia artificial y machine learning para automatizar tareas tradicionalmente manuales de gestión de bases de datos: tuning, patching, backups, optimización de consultas, y detección de anomalías. Oracle Autonomous Database, por ejemplo, promete autotuning, autoscaling, y self-securing con intervención humana mínima. La visión consiste en reducir dramáticamente costos operacionales y complejidad, permitiendo que organizaciones se enfoquen en lógica de aplicación en lugar de gestión de infraestructura. Sin embargo, la autonomía completa permanece aspiracional: sistemas actuales requieren todavía supervisión y configuración humana significativas.
    </p>

    <h3>5.2 Databases as a Service (DBaaS) y Serverless</h3>

    <p>
        Los servicios de bases de datos cloud-managed abstraen complejidades de aprovisionamiento, configuración, patching, backups, y scaling. Proveedores cloud ofrecen servicios managed para diversos SGBD: Amazon RDS, Azure Database, Google Cloud SQL. Los modelos serverless como Aurora Serverless, Azure SQL Database Serverless, y DynamoDB on-demand escalan automáticamente compute y cobran granularmente por uso real, eliminando necesidad de provisionar capacidad anticipadamente. Estos modelos resultan atractivos para cargas de trabajo variables o aplicaciones que requieren elasticidad extrema.
    </p>

    <h3>5.3 Integración de Machine Learning y Bases de Datos</h3>

    <p>
        La convergencia de machine learning y bases de datos se manifiesta en múltiples formas. Bases de datos incorporan capacidades ML nativas: BigQuery ML permite entrenar modelos directamente en BigQuery con SQL, PostgreSQL incluye extensiones para ML, Oracle incluye Oracle Machine Learning. Esta integración reduce fricción de mover datos entre sistemas. Inversamente, frameworks ML adoptan abstracciones tipo base de datos: Feature Stores gestionan features para ML como bases de datos gestionan datos transaccionales. La optimización de consultas se beneficia de ML para predicción de selectividad, generación de índices, y estimación de costos.
    </p>

    <h3>5.4 Blockchain y Distributed Ledgers</h3>

    <p>
        Las tecnologías de distributed ledger proporcionan bases de datos distribuidas inmutables sin autoridad central, garantizando integridad mediante criptografía y consenso distribuido. Aunque popularizadas por criptomonedas, blockchains privadas o permissionadas encuentran aplicaciones empresariales en cadenas de suministro, trazabilidad, contratos inteligentes, y registros auditables. Sistemas como Hyperledger Fabric, Corda, y Quorum proporcionan plataformas blockchain empresariales. Sin embargo, limitaciones significativas de rendimiento, escalabilidad y complejidad operacional limitan adopción generalizada. La apropiabilidad de blockchain debe evaluarse críticamente: muchos casos de uso pueden resolverse efectivamente con bases de datos tradicionales.
    </p>

    <h3>5.5 Quantum Databases</h3>

    <p>
        La computación cuántica, aunque todavía en fases tempranas, promete revolucionar procesamiento de ciertos tipos de consultas. Algoritmos cuánticos como Grover's search ofrecen aceleración cuadrática para búsqueda no estructurada. Bases de datos cuánticas teóricas podrían proporcionar ventajas para ciertos tipos de consultas sobre datos masivos. Sin embargo, la computación cuántica práctica enfrenta desafíos formidables de decoherencia, corrección de errores, y escalabilidad. Las aplicaciones prácticas de bases de datos cuánticas probablemente permanecen distantes en el futuro, pero representan dirección de investigación intrigante.
    </p>

    <h2>6. Mejores Prácticas y Consideraciones de Diseño</h2>

    <p>
        El diseño efectivo de sistemas de bases de datos requiere considerar múltiples dimensiones: modelado de datos, normalización apropiada, selección de tecnología, estrategias de sharding y replicación, planes de backup y recuperación, seguridad, y monitoreo. Las mejores prácticas varían según contexto, pero ciertos principios generales prevalecen. La normalización reduce redundancia y anomalías de actualización, pero la desnormalización puede mejorar rendimiento de lecturas. El diseño debe anticipar patrones de acceso predominantes.
    </p>

    <p>
        La selección de tecnología debe evaluarse rigurosamente contra requisitos específicos: volumen de datos, patrones de acceso (lectura-pesado vs escritura-pesado), requisitos de consistencia, latencia, throughput, y complejidad operacional aceptable. La observabilidad mediante métricas comprehensivas (latencia de consultas, throughput, tasa de errores, utilización de recursos) resulta crítica para operación confiable. Los planes de disaster recovery deben probarse regularmente: backups no verificados no ofrecen garantías. La seguridad requiere defensa en profundidad: encriptación en reposo y en tránsito, autenticación fuerte, principio de privilegio mínimo, y auditoría de accesos.
    </p>

    <div class="mermaid">
    graph TB
        A[Consideraciones de Diseño de BD] --> B[Modelado de Datos]
        A --> C[Rendimiento]
        A --> D[Escalabilidad]
        A --> E[Disponibilidad]
        A --> F[Seguridad]

        B --> B1[Normalización]
        B --> B2[Desnormalización]
        B --> B3[Patrones de Acceso]

        C --> C1[Indexación]
        C --> C2[Particionamiento]
        C --> C3[Caching]
        C --> C4[Optimización de Consultas]

        D --> D1[Sharding]
        D --> D2[Escalamiento Vertical]
        D --> D3[Escalamiento Horizontal]

        E --> E1[Replicación]
        E --> E2[Failover Automático]
        E --> E3[Backup y Recuperación]

        F --> F1[Encriptación]
        F --> F2[Control de Acceso]
        F --> F3[Auditoría]

        style A fill:#9b59b6
        style B fill:#3498db
        style C fill:#e74c3c
        style D fill:#2ecc71
    </div>

    <h2>7. Caso de Estudio: Migración a Arquitectura de Bases de Datos Distribuida</h2>

    <p>
        Este caso de estudio examina la migración de una aplicación de red social de base de datos relacional monolítica a arquitectura distribuida heterogénea, ilustrando desafíos técnicos, decisiones de diseño, y lecciones aprendidas.
    </p>

    <h3>7.1 Contexto Inicial y Desafíos</h3>

    <p>
        La red social "SocialConnect" operaba con base de datos PostgreSQL única manejando todos los datos: perfiles de usuario, publicaciones, comentarios, relaciones de amistad, mensajes, notificaciones, y actividad de usuario. Con 50 millones de usuarios registrados y 10 millones de usuarios activos diarios, el sistema enfrentaba cuellos de botella críticos. Las consultas de feeds personalizados (que requieren joins complejos sobre grafos de relaciones sociales) experimentaban latencias de 5-10 segundos durante horas pico. Las escrituras de publicaciones y comentarios causaban contención de locks. Los backups nocturnos requerían 6 horas, impactando disponibilidad.
    </p>

    <p>
        El análisis reveló patrones de acceso heterogéneos: lecturas dominaban masivamente sobre escrituras (ratio 100:1), ciertos datos (perfiles de usuario) se accedían extremadamente frecuentemente pero raramente cambiaban, las relaciones de amistad formaban grafo complejo consultado frecuentemente, y mensajes requerían acceso rápido pero solo entre usuarios específicos. La tabla de publicaciones contenía 10 billones de registros y crecía 100 millones diarios. Escalar verticalmente el servidor PostgreSQL resultaba prohibitivamente costoso y no sostenible. Se requería estrategia fundamental diferente.
    </p>

    <h3>7.2 Arquitectura Distribuida Diseñada</h3>

    <p>
        El diseño adoptó persistencia políglota con múltiples tecnologías especializadas. Los perfiles de usuario migraron a MongoDB por flexibilidad de esquema (diferentes usuarios tienen atributos variables) y excelente rendimiento de lectura con sharding. Las relaciones de amistad (grafo social) migraron a Neo4j, optimizando consultas de grafos como "amigos de amigos" o "camino más corto entre usuarios". Las publicaciones y comentarios migraron a Cassandra, aprovechando escrituras ultra-rápidas, particionamiento automático, y replicación multi-datacenter.
    </p>

    <p>
        Los mensajes directos migraron a base de datos clave-valor (Redis) para latencias submilisegundo y expiración automática de mensajes antiguos. Las imágenes y videos se almacenaron en Amazon S3 con referencias en bases de datos respectivas. El feed de actividad en tiempo real se implementó mediante Kafka, permitiendo múltiples consumidores procesar stream de eventos independientemente. Esta arquitectura heterogénea permitió optimizar cada tipo de dato según sus características y patrones de acceso específicos.
    </p>

    <div class="mermaid">
    flowchart TB
        App[Aplicación SocialConnect]

        App --> ProfileService[Profile Service]
        App --> SocialService[Social Graph Service]
        App --> FeedService[Feed Service]
        App --> MessageService[Message Service]
        App --> MediaService[Media Service]

        ProfileService --> MongoDB[(MongoDB\nPerfiles Usuario)]
        SocialService --> Neo4j[(Neo4j\nGrafo Social)]
        FeedService --> Cassandra[(Cassandra\nPublicaciones)]
        MessageService --> Redis[(Redis\nMensajes)]
        MediaService --> S3[(S3\nImágenes/Videos)]

        FeedService -.->|Eventos| Kafka[Kafka Stream]
        SocialService -.->|Consume| Kafka

        Cache[Redis Cache] -.->|Acelera| ProfileService
        Cache -.->|Acelera| SocialService

        style App fill:#9b59b6
        style Kafka fill:#e74c3c
        style Cache fill:#f39c12
    </div>

    <h3>7.3 Gestión de Consistencia Distribuida</h3>

    <p>
        El desafío mayor fue gestionar consistencia sin transacciones ACID distribuidas. Se adoptó consistencia eventual con estrategias específicas por caso de uso. Cuando usuario publica contenido, la escritura se confirma en Cassandra y evento se publica a Kafka; consumidores eventualmente actualizan índices de búsqueda y caches. Si usuario actualiza perfil en MongoDB, eventos actualizan copia desnormalizada en feeds. Para operaciones críticas como pagos de suscripciones premium, se implementó Saga Pattern: secuencia coordinada de transacciones locales con compensaciones en caso de fallo.
    </p>

    <p>
        Los conflictos de escrituras concurrentes se resolvieron mediante timestamps y resolución tipo "last-write-wins" para casos no críticos, y mediante conflict-free replicated data types (CRDTs) para contadores (likes, shares). El sistema acepta inconsistencias temporales (feed de usuario puede mostrar contenido eliminado por 1-2 segundos hasta propagación de evento de eliminación) a cambio de disponibilidad y rendimiento. Esta decisión arquitectónica fundamental refleja priorización de disponibilidad sobre consistencia fuerte, apropiada para red social.
    </p>

    <h3>7.4 Resultados y Lecciones Aprendidas</h3>

    <p>
        Post-migración, el sistema logró mejoras dramáticas: latencia de generación de feeds redujo de 5-10 segundos a 200-300 milisegundos, throughput de escrituras incrementó 10x permitiendo soportar 50 millones de publicaciones diarias, disponibilidad mejoró de 99.5% a 99.95% mediante eliminación de punto único de falla, y costos de infraestructura se redujeron 40% mediante uso de hardware commodity horizontal versus servidores especializados costosos verticales.
    </p>

    <p>
        Sin embargo, la complejidad operacional incrementó significativamente: múltiples bases de datos requieren expertise diverso, debugging de problemas cross-system resulta complejo, y testing de consistencia eventual requiere estrategias sofisticadas. Las lecciones clave incluyen: migrar incrementalmente (big-bang migration resulta riesgosa), invertir fuertemente en observabilidad desde inicio, documentar detalladamente decisiones de consistencia, y establecer runbooks para escenarios de inconsistencia. La migración validó que para sistemas de escala masiva con patrones de acceso heterogéneos, arquitecturas distribuidas especializadas resultan superiores a bases de datos monolíticas generalistas.
    </p>

    <h2>8. Técnicas Avanzadas de Optimización</h2>

    <h3>8.1 Particionamiento y Sharding</h3>

    <p>
        El particionamiento horizontal (sharding) divide datos en subconjuntos independientes distribuidos en múltiples servidores, permitiendo escalamiento horizontal. Las estrategias de sharding incluyen range-based sharding (datos particionados por rangos de clave, apropiado cuando consultas frecuentemente filtran por rango pero puede causar hotspots), hash-based sharding (hash de clave determina shard, proporciona distribución uniforme pero dificulta consultas por rango), y directory-based sharding (mapping table indica ubicación de cada registro, flexible pero introduce punto centralizado de consulta).
    </p>

    <p>
        El diseño efectivo de estrategia de sharding requiere comprender patrones de acceso: la clave de sharding debe distribuir carga uniformemente, minimizar consultas cross-shard (que requieren coordinación costosa), y alinear con patrones de consulta comunes. Por ejemplo, para aplicación de e-commerce, sharding por customer_id alinea bien con patrón donde cada usuario accede primariamente sus propios datos. El re-sharding (redistribución de datos cuando se agregan shards) representa operación compleja que debe planificarse cuidadosamente; algunas bases de datos como Cassandra lo manejan automáticamente, otras requieren intervención manual.
    </p>

    <h3>8.2 Estrategias de Caching Multinivel</h3>

    <p>
        El caching reduce latencia y carga en bases de datos almacenando datos frecuentemente accedidos en almacenamiento más rápido. Las arquitecturas típicamente implementan caching multinivel: cache en aplicación (datos en memoria del proceso de aplicación, latencia mínima pero no compartido entre instancias), cache distribuido como Redis o Memcached (compartido entre instancias de aplicación, latencia baja, soporta invalidación coordinada), y cache de resultado de consultas en base de datos misma.
    </p>

    <p>
        Las políticas de invalidación de cache incluyen time-to-live (TTL) donde entradas expiran después de tiempo predeterminado, invalidación explícita donde aplicación invalida cache cuando actualiza datos subyacentes, y write-through donde escrituras actualizan cache y base de datos simultáneamente. El cache stampede (múltiples instancias intentan regenerar mismo cache entry simultáneamente después de expiración) se mitiga mediante locking o probabilistic early expiration. El ratio de cache hit apropiado depende del contexto: para datos altamente accedidos como configuración, 99% resulta deseable; para búsquedas variadas, 60-70% puede resultar aceptable.
    </p>

    <h3>8.3 Replicación para Lectura y Disponibilidad</h3>

    <p>
        La replicación mantiene copias de datos en múltiples nodos, proporcionando alta disponibilidad (si primario falla, réplica puede promover), disaster recovery (réplicas en diferentes regiones geográficas), y escalamiento de lecturas (consultas de solo-lectura se distribuyen entre réplicas). La replicación síncrona confirma escritura solo después que réplicas reconocen, garantizando consistencia fuerte pero incrementando latencia. La replicación asíncrona confirma escritura sin esperar réplicas, minimizando latencia pero arriesgando pérdida de datos si primario falla antes de replicar.
    </p>

    <p>
        La topología de replicación puede ser primario-réplica (arquitectura más común donde primario maneja escrituras y réplicas lecturas), multi-primario (múltiples nodos aceptan escrituras, requiere resolución de conflictos), o peer-to-peer (todos los nodos son iguales). La configuración apropiada depende de requisitos: sistemas financieros priorizan replicación síncrona para consistencia; aplicaciones de consumo masivo frecuentemente aceptan replicación asíncrona para mejor rendimiento. El lag de replicación (retraso entre primario y réplicas) debe monitorearse: lag excesivo puede causar lecturas de datos obsoletos significativamente.
    </p>

    <h2>9. Ejercicios Prácticos</h2>

    <h3>9.1 Ejercicio de Diseño de Base de Datos</h3>

    <p>
        <strong>Escenario:</strong> Diseñe esquema de base de datos para plataforma de comercio electrónico que debe manejar: catálogo de 10 millones de productos con atributos variables por categoría, 100 millones de usuarios, órdenes de compra con múltiples items y diferentes estados, inventario en 500 almacenes con sincronización en tiempo real, reviews de productos con votos de utilidad, y sistema de recomendaciones basado en historial de compras.
    </p>

    <p>
        <strong>Tarea:</strong> (1) Diseñe modelo relacional normalizado para datos transaccionales críticos (usuarios, órdenes, pagos); (2) Justifique dónde aplicar desnormalización para optimizar lecturas; (3) Proponga uso de base de datos NoSQL para componentes específicos, justificando selección de tipo (documental, clave-valor, grafo, columnar); (4) Diseñe estrategia de sharding para tabla de órdenes proyectando 500 millones de órdenes anuales; (5) Proponga índices específicos justificando cada uno con consultas que acelera; (6) Diseñe estrategia de caching multinivel para componentes de alta demanda.
    </p>

    <h3>9.2 Ejercicio de Optimización de Consultas</h3>

    <p>
        <strong>Escenario:</strong> Una consulta SQL crítica para dashboard analítico ejecuta en 45 segundos, inaceptable para uso interactivo. La consulta involucra joins de 5 tablas grandes (millones de registros), múltiples agregaciones, y filtros complejos. Plan de ejecución muestra table scans completos en tablas grandes y sorts costosos.
    </p>

    <p>
        <strong>Tarea:</strong> (1) Analice plan de ejecución identificando operaciones más costosas; (2) Proponga índices específicos que mejorarían performance, justificando cada uno; (3) Considere reescritura de consulta para facilitar uso de índices; (4) Evalúe si materializar vista sería apropiado, considerando trade-offs; (5) Proponga estrategia de particionamiento de tablas grandes si aplicable; (6) Diseñe prueba de carga para validar mejoras bajo condiciones realistas; (7) Estime mejora de performance esperada para cada optimización propuesta.
    </p>

    <h3>9.3 Ejercicio de Selección de Tecnología</h3>

    <p>
        <strong>Escenario:</strong> Su equipo debe seleccionar tecnología de base de datos para nuevo proyecto. Considere tres casos de uso distintos: (A) Sistema bancario procesando transacciones financieras donde consistencia es absoluta; (B) Aplicación de analytics procesando billones de eventos de telemetría de IoT con consultas ad-hoc complejas; (C) Plataforma de gaming en tiempo real con 10 millones de usuarios concurrentes requiriendo latencias sub-10ms.
    </p>

    <p>
        <strong>Tarea:</strong> Para cada caso de uso: (1) Identifique requisitos críticos de base de datos (consistencia, disponibilidad, latencia, throughput, escalabilidad); (2) Evalúe tres tecnologías candidatas contra requisitos, considerando SQL vs NoSQL, tipo de NoSQL si aplicable, y opciones específicas; (3) Analice trade-offs de cada opción usando framework CAP y consideraciones de performance; (4) Haga recomendación justificada con criterios claros; (5) Identifique riesgos de su selección y estrategias de mitigación; (6) Proponga plan de validación mediante prueba de concepto o benchmark.
    </p>

    <div class="highlight-box">
        <h3>Resumen de la Clase</h3>
        <p>
            Esta clase ha explorado elementos avanzados de bases de datos, cubriendo evolución de paradigmas NoSQL, optimización de rendimiento, Big Data y procesamiento distribuido, bases de datos especializadas, y tendencias emergentes. El dominio de tecnologías avanzadas de bases de datos resulta esencial para especialistas en Ingeniería de Software, dado que decisiones de gestión de datos impactan profundamente rendimiento, escalabilidad y confiabilidad de sistemas de software modernos.
        </p>
    </div>

    <div class="nav-buttons">
        <a href="#" class="btn btn-prev" data-clase="clase4">← Anterior: Diseño y Arquitectura</a>
        <a href="#" class="btn btn-next" data-clase="clase6">Siguiente: Verificación Formal →</a>
    </div>
</div>
